{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A minimal example to demonstrate how prototype new MlflowloggerV2 (tentative name) class works to log artifacts in additional to train loss/metrics. \n",
    "\n",
    "Meant to serve as grounds to discuss design questions, and hopefully a real feature PR will follow this.\n",
    "\n",
    "Is dependent on the files produced by 1.illumination_correction/0.create_loaddata_csvs ALSF pilot data repo https://github.com/WayScience/pediatric_cancer_atlas_profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weishanli/anaconda3/envs/speckle_analysis/lib/python3.11/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.8' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(str(pathlib.Path('.').absolute().parent.parent))\n",
    "\n",
    "## Dataset\n",
    "from virtual_stain_flow.datasets.PatchDataset import PatchDataset\n",
    "\n",
    "## FNet training\n",
    "from virtual_stain_flow.models.fnet import FNet\n",
    "\n",
    "from virtual_stain_flow.transforms.MinMaxNormalize import MinMaxNormalize\n",
    "\n",
    "## Metrics\n",
    "from virtual_stain_flow.metrics.MetricsWrapper import MetricsWrapper\n",
    "from virtual_stain_flow.metrics.PSNR import PSNR\n",
    "from virtual_stain_flow.metrics.SSIM import SSIM\n",
    "\n",
    "from virtual_stain_flow.trainers.TrainerV2 import TrainerV2\n",
    "from virtual_stain_flow.logging.MlflowLoggerV2 import MlflowLoggerV2\n",
    "from virtual_stain_flow.logging.callbacks.PlotCallback import PlotPredictionCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANALYSIS_REPO_ROOT = pathlib.Path('.').absolute().parent.parent / 'pediatric_cancer_atlas_analysis'\n",
    "CONFIG_PATH = ANALYSIS_REPO_ROOT / 'config.yml'\n",
    "config = yaml.safe_load(CONFIG_PATH.read_text())\n",
    "\n",
    "LOADDATA_FILE_PATH = ANALYSIS_REPO_ROOT / '0.data_preprocessing' / 'data_split_loaddata' / 'loaddata_train.csv'\n",
    "assert LOADDATA_FILE_PATH.exists(), f\"File not found: {LOADDATA_FILE_PATH}\" \n",
    "\n",
    "PROFILING_DIR = pathlib.Path(config['paths']['pediatric_cancer_atlas_profiling_path'])\n",
    "assert PROFILING_DIR.exists(), f\"Directory not found: {PROFILING_DIR}\"\n",
    "\n",
    "SC_FEATURES_DIR = pathlib.Path(config['paths']['sc_features_path'])\n",
    "assert SC_FEATURES_DIR.exists(), f\"Directory not found: {SC_FEATURES_DIR}\"\n",
    "\n",
    "INPUT_CHANNEL_NAMES = config['data']['input_channel_keys']\n",
    "TARGET_CHANNEL_NAMES = config['data']['target_channel_keys']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some parameters for minimal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "CONV_DEPTH = 5\n",
    "LR = 1e-4\n",
    "BETAS = (0.5, 0.9)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "PATIENCE = 20 # no real early stopping here for demo purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaddata_df = pd.read_csv(LOADDATA_FILE_PATH)\n",
    "sc_features = pd.DataFrame()\n",
    "for plate in loaddata_df['Metadata_Plate'].unique():\n",
    "    sc_features_parquet = SC_FEATURES_DIR / f'{plate}_sc_normalized.parquet'\n",
    "    if not sc_features_parquet.exists():\n",
    "        print(f'{sc_features_parquet} does not exist, skipping...')\n",
    "        continue \n",
    "    else:\n",
    "        sc_features = pd.concat([\n",
    "            sc_features, \n",
    "            pd.read_parquet(\n",
    "                sc_features_parquet,\n",
    "                columns=['Metadata_Plate', 'Metadata_Well', 'Metadata_Site', 'Metadata_Cells_Location_Center_X', 'Metadata_Cells_Location_Center_Y']\n",
    "            )\n",
    "        ])\n",
    "\n",
    "pds = PatchDataset(\n",
    "        _loaddata_csv=loaddata_df,\n",
    "        _sc_feature=sc_features,\n",
    "        _input_channel_keys=INPUT_CHANNEL_NAMES,\n",
    "        _target_channel_keys=TARGET_CHANNEL_NAMES,\n",
    "        _input_transform=None,\n",
    "        _target_transform=None,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        verbose=False,\n",
    "        patch_generation_method=\"random_cell\",\n",
    "        n_expected_patches_per_img=50,\n",
    "        patch_generation_random_seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds.set_input_channel_keys(INPUT_CHANNEL_NAMES)that are like the old classes with \n",
    "pds.set_target_channel_keys(TARGET_CHANNEL_NAMES[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configure the dataset with normalization methods\n",
    "pds.set_input_transform(MinMaxNormalize(_normalization_factor=(2 ** 16) - 1, _always_apply=True, _p=1.0))\n",
    "pds.set_target_transform(MinMaxNormalize(_normalization_factor=(2 ** 16) - 1, _always_apply=True, _p=1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define where the test logging outptus go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_DIR = pathlib.Path('.').absolute() / 'test_mlflow'\n",
    "MLFLOW_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PLOT_DIR = pathlib.Path('.').absolute() / 'test_plots'\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fns = {\n",
    "        \"mse_loss\": MetricsWrapper(_metric_name='mse', module=torch.nn.MSELoss()),\n",
    "        \"ssim_loss\": SSIM(_metric_name=\"ssim\"),\n",
    "        \"psnr_loss\": PSNR(_metric_name=\"psnr\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNet(\n",
    "    depth=CONV_DEPTH,\n",
    "    output_activation='sigmoid'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            \"lr\": LR,\n",
    "            \"beta0\": BETAS[0],\n",
    "            \"beta1\": BETAS[1],\n",
    "            \"depth\": CONV_DEPTH,\n",
    "            \"patch_size\": PATCH_SIZE,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"patience\": PATIENCE,\n",
    "            \"input_norm\": 'min_max',\n",
    "            \"target_norm\": 'min_max',\n",
    "            \"channel_name\": TARGET_CHANNEL_NAMES[0],\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize logger and callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_callback = PlotPredictionCallback(\n",
    "    name='plot_callback1',\n",
    "    save_path=PLOT_DIR,\n",
    "    dataset=pds,\n",
    "    every_n_epochs=1,\n",
    "    # kwargs passed to plotter\n",
    "    show_plot=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = MlflowLoggerV2(\n",
    "    name='logger1',\n",
    "    tracking_uri = str(MLFLOW_DIR / 'mlruns'),\n",
    "    experiment_name='test_logging',\n",
    "    run_name='test_run1',\n",
    "    experiment_type='training',\n",
    "    model_architecture='FNet',\n",
    "    target_channel_name=TARGET_CHANNEL_NAMES[0],\n",
    "    tags={},\n",
    "    mlflow_log_params_args=params,\n",
    "    callbacks=[plot_callback]    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, initialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR, betas=BETAS)\n",
    "backprop_loss = torch.nn.L1Loss()\n",
    "trainer = TrainerV2(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    backprop_loss=backprop_loss,\n",
    "    dataset=pds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    patience=PATIENCE,\n",
    "    metrics=metric_fns,\n",
    "    device='cuda',\n",
    "    early_termination_metric=backprop_loss.__class__.__name__\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bind logger to trainer during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additionall Logging (concept, not yet Implemented)\n",
    "\n",
    "Before explicitly telling mlflow to stop run, user gets to log additional stuff if applicable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.log_dataset(pds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.log_artifact(...)\n",
    "# logger.log_additional_stuff(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicitly end run\n",
    "After logging everything needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.end_run()\n",
    "\"\"\"\n",
    "or\n",
    "\"\"\"\n",
    "# logger.end_run()\n",
    "\"\"\"\n",
    "or just\n",
    "\"\"\"\n",
    "del logger # end run is automatically done in the destructor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Mlflow experiment and run(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "run_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "experiment_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "status",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "artifact_uri",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "start_time",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "end_time",
         "rawType": "datetime64[ns, UTC]",
         "type": "unknown"
        },
        {
         "name": "metrics.val_psnr_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.train_ssim_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.train_L1Loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.val_mse_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.train_psnr_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.val_ssim_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.val_L1Loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "metrics.train_mse_loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "params.lr",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.patience",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.depth",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.patch_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.beta0",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.batch_size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.input_norm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.channel_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.target_norm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.epochs",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "params.beta1",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tags.mlflow.source.name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tags.mlflow.user",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tags.mlflow.source.type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tags.mlflow.runName",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8a241042-1884-4487-81e4-b96bfe70ce5f",
       "rows": [
        [
         "0",
         "699442221ca4415ab1d61a4285e9058a",
         "0",
         "FINISHED",
         "/home/weishanli/Waylab/virtual_stain_flow/examples/test_mlflow/mlruns/0/699442221ca4415ab1d61a4285e9058a/artifacts",
         "2025-06-19 20:58:12.229000+00:00",
         "2025-06-19 21:09:56.484000+00:00",
         "32.71019744873047",
         "34.213661193847656",
         "0.011016172572311496",
         "32.71019744873047",
         "34.213661193847656",
         "32.71019744873047",
         "0.01307505540899001",
         "34.213661193847656",
         "0.0001",
         "20",
         "5",
         "256",
         "0.5",
         "16",
         "min_max",
         "OrigDNA",
         "min_max",
         "10",
         "0.9",
         "/home/weishanli/anaconda3/envs/speckle_analysis/lib/python3.11/site-packages/ipykernel_launcher.py",
         "weishanli",
         "LOCAL",
         "bustling-seal-758"
        ]
       ],
       "shape": {
        "columns": 29,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>status</th>\n",
       "      <th>artifact_uri</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>metrics.val_psnr_loss</th>\n",
       "      <th>metrics.train_ssim_loss</th>\n",
       "      <th>metrics.train_L1Loss</th>\n",
       "      <th>metrics.val_mse_loss</th>\n",
       "      <th>...</th>\n",
       "      <th>params.batch_size</th>\n",
       "      <th>params.input_norm</th>\n",
       "      <th>params.channel_name</th>\n",
       "      <th>params.target_norm</th>\n",
       "      <th>params.epochs</th>\n",
       "      <th>params.beta1</th>\n",
       "      <th>tags.mlflow.source.name</th>\n",
       "      <th>tags.mlflow.user</th>\n",
       "      <th>tags.mlflow.source.type</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>699442221ca4415ab1d61a4285e9058a</td>\n",
       "      <td>0</td>\n",
       "      <td>FINISHED</td>\n",
       "      <td>/home/weishanli/Waylab/virtual_stain_flow/exam...</td>\n",
       "      <td>2025-06-19 20:58:12.229000+00:00</td>\n",
       "      <td>2025-06-19 21:09:56.484000+00:00</td>\n",
       "      <td>32.710197</td>\n",
       "      <td>34.213661</td>\n",
       "      <td>0.011016</td>\n",
       "      <td>32.710197</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>min_max</td>\n",
       "      <td>OrigDNA</td>\n",
       "      <td>min_max</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "      <td>/home/weishanli/anaconda3/envs/speckle_analysi...</td>\n",
       "      <td>weishanli</td>\n",
       "      <td>LOCAL</td>\n",
       "      <td>bustling-seal-758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             run_id experiment_id    status  \\\n",
       "0  699442221ca4415ab1d61a4285e9058a             0  FINISHED   \n",
       "\n",
       "                                        artifact_uri  \\\n",
       "0  /home/weishanli/Waylab/virtual_stain_flow/exam...   \n",
       "\n",
       "                        start_time                         end_time  \\\n",
       "0 2025-06-19 20:58:12.229000+00:00 2025-06-19 21:09:56.484000+00:00   \n",
       "\n",
       "   metrics.val_psnr_loss  metrics.train_ssim_loss  metrics.train_L1Loss  \\\n",
       "0              32.710197                34.213661              0.011016   \n",
       "\n",
       "   metrics.val_mse_loss  ...  params.batch_size  params.input_norm  \\\n",
       "0             32.710197  ...                 16            min_max   \n",
       "\n",
       "   params.channel_name  params.target_norm params.epochs params.beta1  \\\n",
       "0              OrigDNA             min_max            10          0.9   \n",
       "\n",
       "                             tags.mlflow.source.name tags.mlflow.user  \\\n",
       "0  /home/weishanli/anaconda3/envs/speckle_analysi...        weishanli   \n",
       "\n",
       "  tags.mlflow.source.type tags.mlflow.runName  \n",
       "0                   LOCAL   bustling-seal-758  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(str(MLFLOW_DIR / 'mlruns'))\n",
    "client = MlflowClient()\n",
    "experiments = client.search_experiments()\n",
    "runs_df = mlflow.search_runs(experiment_ids=[experiments[0].experiment_id])\n",
    "runs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the current Implementation and single callback the only artifacts produced will be the best model weights and the prediction plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plots/epoch/plot_predictions/epoch_1.png\n",
      "plots/epoch/plot_predictions/epoch_10.png\n",
      "plots/epoch/plot_predictions/epoch_2.png\n",
      "plots/epoch/plot_predictions/epoch_3.png\n",
      "plots/epoch/plot_predictions/epoch_4.png\n",
      "plots/epoch/plot_predictions/epoch_5.png\n",
      "plots/epoch/plot_predictions/epoch_6.png\n",
      "plots/epoch/plot_predictions/epoch_7.png\n",
      "plots/epoch/plot_predictions/epoch_8.png\n",
      "plots/epoch/plot_predictions/epoch_9.png\n",
      "weights/best/logger1_model_epoch_10.pth\n"
     ]
    }
   ],
   "source": [
    "run_id = runs_df['run_id'].iloc[0]\n",
    "def list_all_artifacts(client, run_id, path=\"\"):\n",
    "    all_paths = []\n",
    "    items = client.list_artifacts(run_id, path)\n",
    "    for item in items:\n",
    "        if item.is_dir:\n",
    "            all_paths.extend(list_all_artifacts(client, run_id, item.path))\n",
    "        else:\n",
    "            all_paths.append(item.path)\n",
    "    return all_paths\n",
    "\n",
    "# Usage\n",
    "all_artifact_paths = list_all_artifacts(client, run_id)\n",
    "for path in all_artifact_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete everything under the example plot and mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./test_mlflow/\n",
    "!rm -rf ./test_plots/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speckle_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
