{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A minimal example to demonstrate how the trainer for FNet and wGaN GP plus the callbacks works along with patched dataset\n",
    "\n",
    "Is will not be dependent on the pe2loaddata generated index file from the ALSF pilot data repo unlike the other example notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weishanli/Waylab\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append(str(pathlib.Path('.').absolute().parent.parent))\n",
    "print(str(pathlib.Path('.').absolute().parent.parent))\n",
    "\n",
    "## Dataset\n",
    "from virtual_stain_flow.datasets.GenericImageDataset import GenericImageDataset\n",
    "from virtual_stain_flow.datasets.CachedDataset import CachedDataset\n",
    "\n",
    "## FNet training\n",
    "from virtual_stain_flow.models.fnet import FNet\n",
    "from virtual_stain_flow.trainers.Trainer import Trainer\n",
    "\n",
    "## wGaN training\n",
    "from virtual_stain_flow.models.unet import UNet\n",
    "from virtual_stain_flow.models.discriminator import GlobalDiscriminator\n",
    "from virtual_stain_flow.trainers.WGaNTrainer import WGaNTrainer\n",
    "\n",
    "## wGaN losses\n",
    "from virtual_stain_flow.losses.GradientPenaltyLoss import GradientPenaltyLoss\n",
    "from virtual_stain_flow.losses.DiscriminatorLoss import DiscriminatorLoss\n",
    "from virtual_stain_flow.losses.GeneratorLoss import GeneratorLoss\n",
    "\n",
    "from virtual_stain_flow.transforms.MinMaxNormalize import MinMaxNormalize\n",
    "\n",
    "## Metrics\n",
    "from virtual_stain_flow.metrics.MetricsWrapper import MetricsWrapper\n",
    "from virtual_stain_flow.metrics.PSNR import PSNR\n",
    "from virtual_stain_flow.metrics.SSIM import SSIM\n",
    "\n",
    "## callback\n",
    "from virtual_stain_flow.callbacks.MlflowLogger import MlflowLogger\n",
    "from virtual_stain_flow.callbacks.IntermediatePlot import IntermediatePatchPlot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify train data and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "EXAMPLE_PATCH_DATA_EXPORT_PATH = '/REPLACE/WITH/PATH/TO/DATA'\n",
    "\n",
    "EXAMPLE_DIR = pathlib.Path('.').absolute() / 'example_train_generic_dataset'\n",
    "EXAMPLE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf example_train_generic_dataset/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = EXAMPLE_DIR / 'plot'\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MLFLOW_DIR =EXAMPLE_DIR / 'mlflow'\n",
    "MLFLOW_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names = [\n",
    "    \"OrigBrightfield\",\n",
    "    \"OrigDNA\",\n",
    "    \"OrigER\",\n",
    "    \"OrigMito\",\n",
    "    \"OrigRNA\",\n",
    "    \"OrigAGP\",\n",
    "]\n",
    "input_channel_name = \"OrigBrightfield\"\n",
    "target_channel_names = [ch for ch in channel_names if ch != input_channel_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Patch dataset and Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 12:06:27,871 - DEBUG - Channel keys: {'OrigRNA', 'OrigAGP', 'OrigER', 'OrigBrightfield', 'OrigDNA', 'OrigMito'} detected\n",
      "2025-02-20 12:06:27,871 - DEBUG - No channel keys specified, skip\n",
      "2025-02-20 12:06:27,871 - DEBUG - No channel keys specified, skip\n",
      "2025-02-20 12:06:27,872 - DEBUG - Setting input transform ...\n",
      "2025-02-20 12:06:27,872 - DEBUG - Setting target transform ...\n",
      "2025-02-20 12:06:27,872 - DEBUG - Set input channel(s) as ['OrigBrightfield']\n",
      "2025-02-20 12:06:27,872 - DEBUG - Set target channel(s) as ['OrigDNA']\n"
     ]
    }
   ],
   "source": [
    "pds = GenericImageDataset(\n",
    "    image_dir=EXAMPLE_PATCH_DATA_EXPORT_PATH,\n",
    "    site_pattern=r\"^([^_]+_[^_]+_[^_]+)\",\n",
    "    channel_pattern=r\"_([^_]+)\\.tiff$\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "## Set input and target channels\n",
    "pds.set_input_channel_keys([input_channel_name])\n",
    "pds.set_target_channel_keys('OrigDNA')\n",
    "\n",
    "## Cache for faster training \n",
    "cds = CachedDataset(\n",
    "    pds,\n",
    "    prefill_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNet trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model without callback and check logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNet(depth=4)\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=None,\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>L1Loss</th>\n",
       "      <th>val_L1Loss</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "      <th>val_psnr</th>\n",
       "      <th>val_ssim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1492.610175</td>\n",
       "      <td>1521.866577</td>\n",
       "      <td>-69.927834</td>\n",
       "      <td>-5.388215e-09</td>\n",
       "      <td>-70.222565</td>\n",
       "      <td>9.050420e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1480.966715</td>\n",
       "      <td>1521.779175</td>\n",
       "      <td>-69.699051</td>\n",
       "      <td>-8.186153e-09</td>\n",
       "      <td>-70.222458</td>\n",
       "      <td>-5.678337e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1761.065009</td>\n",
       "      <td>1521.689453</td>\n",
       "      <td>-70.673164</td>\n",
       "      <td>-5.811710e-09</td>\n",
       "      <td>-70.222351</td>\n",
       "      <td>-1.330130e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1517.153781</td>\n",
       "      <td>1521.613159</td>\n",
       "      <td>-70.176323</td>\n",
       "      <td>-7.637948e-09</td>\n",
       "      <td>-70.222244</td>\n",
       "      <td>-1.183239e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1555.365207</td>\n",
       "      <td>1521.635498</td>\n",
       "      <td>-70.198990</td>\n",
       "      <td>-7.835469e-09</td>\n",
       "      <td>-70.222260</td>\n",
       "      <td>-7.694487e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1719.525974</td>\n",
       "      <td>1521.537537</td>\n",
       "      <td>-70.295540</td>\n",
       "      <td>-5.934725e-09</td>\n",
       "      <td>-70.222168</td>\n",
       "      <td>-8.564919e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1489.472738</td>\n",
       "      <td>1521.481323</td>\n",
       "      <td>-69.753349</td>\n",
       "      <td>-8.170694e-09</td>\n",
       "      <td>-70.222076</td>\n",
       "      <td>-1.564081e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1703.764418</td>\n",
       "      <td>1521.477356</td>\n",
       "      <td>-70.690598</td>\n",
       "      <td>-4.165215e-09</td>\n",
       "      <td>-70.222092</td>\n",
       "      <td>-1.391449e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1656.319485</td>\n",
       "      <td>1521.448120</td>\n",
       "      <td>-70.481544</td>\n",
       "      <td>-4.851262e-09</td>\n",
       "      <td>-70.222031</td>\n",
       "      <td>-1.076659e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1514.457506</td>\n",
       "      <td>1521.436646</td>\n",
       "      <td>-70.083336</td>\n",
       "      <td>-2.934100e-09</td>\n",
       "      <td>-70.222023</td>\n",
       "      <td>-1.150742e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch       L1Loss   val_L1Loss       psnr          ssim   val_psnr  \\\n",
       "0      1  1492.610175  1521.866577 -69.927834 -5.388215e-09 -70.222565   \n",
       "1      2  1480.966715  1521.779175 -69.699051 -8.186153e-09 -70.222458   \n",
       "2      3  1761.065009  1521.689453 -70.673164 -5.811710e-09 -70.222351   \n",
       "3      4  1517.153781  1521.613159 -70.176323 -7.637948e-09 -70.222244   \n",
       "4      5  1555.365207  1521.635498 -70.198990 -7.835469e-09 -70.222260   \n",
       "5      6  1719.525974  1521.537537 -70.295540 -5.934725e-09 -70.222168   \n",
       "6      7  1489.472738  1521.481323 -69.753349 -8.170694e-09 -70.222076   \n",
       "7      8  1703.764418  1521.477356 -70.690598 -4.165215e-09 -70.222092   \n",
       "8      9  1656.319485  1521.448120 -70.481544 -4.851262e-09 -70.222031   \n",
       "9     10  1514.457506  1521.436646 -70.083336 -2.934100e-09 -70.222023   \n",
       "\n",
       "       val_ssim  \n",
       "0  9.050420e-11  \n",
       "1 -5.678337e-10  \n",
       "2 -1.330130e-09  \n",
       "3 -1.183239e-09  \n",
       "4 -7.694487e-09  \n",
       "5 -8.564919e-09  \n",
       "6 -1.564081e-09  \n",
       "7 -1.391449e-08  \n",
       "8 -1.076659e-09  \n",
       "9 -1.150742e-09  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(trainer.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with alternative early termination metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early termination at epoch 6 with best validation metric -70.41797637939453\n"
     ]
    }
   ],
   "source": [
    "model = FNet(depth=4)\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=None,\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda',\n",
    "    early_termination_metric = 'psnr' # set early termination metric as psnr for the sake of demonstration\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with mlflow logger callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'lr': 3e-4\n",
    "        },\n",
    "    )\n",
    "\n",
    "del trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=[mlflow_logger_callback],\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wGaN GP example with mlflow logger callback and plot callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNet(\n",
    "    n_channels=1,\n",
    "    n_classes=1\n",
    ")\n",
    "\n",
    "discriminator = GlobalDiscriminator(\n",
    "    n_in_channels = 2,\n",
    "    n_in_filters = 64,\n",
    "    _conv_depth = 4,\n",
    "    _pool_before_fc = True\n",
    ")\n",
    "\n",
    "generator_optimizer = optim.Adam(generator.parameters(), \n",
    "                                 lr=0.0002, \n",
    "                                 betas=(0., 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), \n",
    "                                     lr=0.00002, \n",
    "                                     betas=(0., 0.9),\n",
    "                                     weight_decay=0.001)\n",
    "\n",
    "gp_loss = GradientPenaltyLoss(\n",
    "    _metric_name='gp_loss',\n",
    "    discriminator=discriminator,\n",
    "    weight=10.0,\n",
    ")\n",
    "\n",
    "gen_loss = GeneratorLoss(\n",
    "    _metric_name='gen_loss'\n",
    ")\n",
    "\n",
    "disc_loss = DiscriminatorLoss(\n",
    "    _metric_name='disc_loss'\n",
    ")\n",
    "\n",
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train_wgan', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'gen_lr': 0.0002,\n",
    "            'disc_lr': 0.00002\n",
    "        },\n",
    "    )\n",
    "\n",
    "wgan_trainer = WGaNTrainer(\n",
    "    dataset=cds,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    patience=20, # setting this to prevent unwanted early termination here\n",
    "    device='cuda',\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gen_optimizer=generator_optimizer,\n",
    "    disc_optimizer=discriminator_optimizer,\n",
    "    generator_loss_fn=gen_loss,\n",
    "    discriminator_loss_fn=disc_loss,\n",
    "    gradient_penalty_fn=gp_loss,\n",
    "    discriminator_update_freq=1,\n",
    "    generator_update_freq=2,\n",
    "    callbacks=[mlflow_logger_callback],\n",
    "    metrics={'ssim': SSIM(_metric_name='ssim'), \n",
    "             'psnr': PSNR(_metric_name='psnr')},\n",
    ")\n",
    "\n",
    "wgan_trainer.train()\n",
    "\n",
    "del generator\n",
    "del wgan_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # wGaN GP example with mlflow logger callback and alternative early termination loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNet(\n",
    "    n_channels=1,\n",
    "    n_classes=1\n",
    ")\n",
    "\n",
    "discriminator = GlobalDiscriminator(\n",
    "    n_in_channels = 2,\n",
    "    n_in_filters = 64,\n",
    "    _conv_depth = 4,\n",
    "    _pool_before_fc = True\n",
    ")\n",
    "\n",
    "generator_optimizer = optim.Adam(generator.parameters(), \n",
    "                                 lr=0.0002, \n",
    "                                 betas=(0., 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), \n",
    "                                     lr=0.00002, \n",
    "                                     betas=(0., 0.9),\n",
    "                                     weight_decay=0.001)\n",
    "\n",
    "gp_loss = GradientPenaltyLoss(\n",
    "    _metric_name='gp_loss',\n",
    "    discriminator=discriminator,\n",
    "    weight=10.0,\n",
    ")\n",
    "\n",
    "gen_loss = GeneratorLoss(\n",
    "    _metric_name='gen_loss'\n",
    ")\n",
    "\n",
    "disc_loss = DiscriminatorLoss(\n",
    "    _metric_name='disc_loss'\n",
    ")\n",
    "\n",
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train_wgan_mae_early_term', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'gen_lr': 0.0002,\n",
    "            'disc_lr': 0.00002\n",
    "        },\n",
    "    )\n",
    "\n",
    "wgan_trainer = WGaNTrainer(\n",
    "    dataset=cds,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    patience=5, # lower patience here\n",
    "    device='cuda',\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gen_optimizer=generator_optimizer,\n",
    "    disc_optimizer=discriminator_optimizer,\n",
    "    generator_loss_fn=gen_loss,\n",
    "    discriminator_loss_fn=disc_loss,\n",
    "    gradient_penalty_fn=gp_loss,\n",
    "    discriminator_update_freq=1,\n",
    "    generator_update_freq=2,\n",
    "    callbacks=[mlflow_logger_callback],\n",
    "    metrics={'ssim': SSIM(_metric_name='ssim'), \n",
    "             'psnr': PSNR(_metric_name='psnr'),\n",
    "             'mae': MetricsWrapper(_metric_name='mae', module=nn.L1Loss()) # use a wrapper for torch nn L1Loss\n",
    "             },\n",
    "    early_termination_metric = 'mae' # update early temrination loss with the supplied L1Loss/mae metric instead of the default GaN generator loss\n",
    ")\n",
    "\n",
    "wgan_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_gan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
