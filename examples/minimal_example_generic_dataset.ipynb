{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A minimal example to demonstrate how the trainer for FNet and wGAN GP plus the callbacks works along with patched dataset\n",
    "\n",
    "Is will not be dependent on the pe2loaddata generated index file from the ALSF pilot data repo unlike the other example notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weishanli/Waylab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weishanli/anaconda3/envs/cp_gan_env/lib/python3.9/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append(str(pathlib.Path('.').absolute().parent.parent))\n",
    "print(str(pathlib.Path('.').absolute().parent.parent))\n",
    "\n",
    "## Dataset\n",
    "from virtual_stain_flow.datasets.GenericImageDataset import GenericImageDataset\n",
    "from virtual_stain_flow.datasets.CachedDataset import CachedDataset\n",
    "\n",
    "## FNet training\n",
    "from virtual_stain_flow.models.fnet import FNet\n",
    "from virtual_stain_flow.trainers.Trainer import Trainer\n",
    "\n",
    "## wGaN training\n",
    "from virtual_stain_flow.models.unet import UNet\n",
    "from virtual_stain_flow.models.discriminator import GlobalDiscriminator\n",
    "from virtual_stain_flow.trainers.WGANTrainer import WGANTrainer\n",
    "\n",
    "## wGaN losses\n",
    "from virtual_stain_flow.losses.GradientPenaltyLoss import GradientPenaltyLoss\n",
    "from virtual_stain_flow.losses.DiscriminatorLoss import WassersteinLoss\n",
    "from virtual_stain_flow.losses.GeneratorLoss import GeneratorLoss\n",
    "\n",
    "from virtual_stain_flow.transforms.MinMaxNormalize import MinMaxNormalize\n",
    "\n",
    "## Metrics\n",
    "from virtual_stain_flow.metrics.MetricsWrapper import MetricsWrapper\n",
    "from virtual_stain_flow.metrics.PSNR import PSNR\n",
    "from virtual_stain_flow.metrics.SSIM import SSIM\n",
    "\n",
    "## callback\n",
    "from virtual_stain_flow.callbacks.MlflowLogger import MlflowLogger\n",
    "from virtual_stain_flow.callbacks.IntermediatePlot import IntermediatePlot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify train data and output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "EXAMPLE_PATCH_DATA_EXPORT_PATH = '/REPLACE/WITH/PATH/TO/DATA'\n",
    "\n",
    "EXAMPLE_DIR = pathlib.Path('.').absolute() / 'example_train_generic_dataset'\n",
    "EXAMPLE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf example_train_generic_dataset/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = EXAMPLE_DIR / 'plot'\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MLFLOW_DIR =EXAMPLE_DIR / 'mlflow'\n",
    "MLFLOW_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_names = [\n",
    "    \"OrigBrightfield\",\n",
    "    \"OrigDNA\",\n",
    "    \"OrigER\",\n",
    "    \"OrigMito\",\n",
    "    \"OrigRNA\",\n",
    "    \"OrigAGP\",\n",
    "]\n",
    "input_channel_name = \"OrigBrightfield\"\n",
    "target_channel_names = [ch for ch in channel_names if ch != input_channel_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Patch dataset and Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-03 20:30:03,223 - DEBUG - Channel keys: {'OrigMito', 'OrigBrightfield', 'OrigDNA', 'OrigRNA', 'OrigER', 'OrigAGP'} detected\n",
      "2025-03-03 20:30:03,225 - DEBUG - No channel keys specified, skip\n",
      "2025-03-03 20:30:03,226 - DEBUG - No channel keys specified, skip\n",
      "2025-03-03 20:30:03,226 - DEBUG - Setting input transform ...\n",
      "2025-03-03 20:30:03,226 - DEBUG - Setting target transform ...\n",
      "2025-03-03 20:30:03,226 - DEBUG - Set input channel(s) as ['OrigBrightfield']\n",
      "2025-03-03 20:30:03,227 - DEBUG - Set target channel(s) as ['OrigDNA']\n"
     ]
    }
   ],
   "source": [
    "ds = GenericImageDataset(\n",
    "    image_dir=EXAMPLE_PATCH_DATA_EXPORT_PATH,\n",
    "    site_pattern=r\"^([^_]+_[^_]+_[^_]+)\",\n",
    "    channel_pattern=r\"_([^_]+)\\.tiff$\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "## Set input and target channels\n",
    "ds.set_input_channel_keys([input_channel_name])\n",
    "ds.set_target_channel_keys('OrigDNA')\n",
    "\n",
    "## Cache for faster training \n",
    "cds = CachedDataset(\n",
    "    ds,\n",
    "    prefill_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNet trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model without callback and check logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNet(depth=4)\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=None,\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda',\n",
    "    early_termination_metric = None\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "epoch",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "L1Loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_L1Loss",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "psnr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ssim",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_psnr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_ssim",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "57db911c-095d-4f8b-8f57-ab73118f2b71",
       "rows": [
        [
         "0",
         "1",
         "1556.9512803819443",
         "1610.1253051757812",
         "-70.28494262695312",
         "9.063276795728825e-10",
         "-70.56584167480469",
         "-8.826770980796539e-10"
        ],
        [
         "1",
         "2",
         "1702.884250217014",
         "1610.0806274414062",
         "-70.88795471191406",
         "-3.853541929998983e-09",
         "-70.56578063964844",
         "-1.0126930405363055e-09"
        ],
        [
         "2",
         "3",
         "1515.5343560112847",
         "1609.9841918945312",
         "-70.11585998535156",
         "-4.895769567525576e-09",
         "-70.56565856933594",
         "-1.7035615140770233e-09"
        ],
        [
         "3",
         "4",
         "1559.3525390625",
         "1609.861083984375",
         "-70.39810943603516",
         "-3.283770810824649e-09",
         "-70.56550598144531",
         "-1.8262883427766496e-09"
        ],
        [
         "4",
         "5",
         "1545.5415174696182",
         "1609.8245849609375",
         "-70.3438491821289",
         "-3.253234126532334e-09",
         "-70.56546020507812",
         "-1.8821437741678437e-09"
        ],
        [
         "5",
         "6",
         "1542.607638888889",
         "1609.786376953125",
         "-70.49755859375",
         "-8.243815630137874e-10",
         "-70.56541442871094",
         "-1.5619402438105112e-09"
        ],
        [
         "6",
         "7",
         "1501.347873263889",
         "1609.7578735351562",
         "-69.79637908935547",
         "3.219659261421981e-10",
         "-70.56538391113281",
         "-1.5038892353658184e-09"
        ],
        [
         "7",
         "8",
         "1526.6503228081597",
         "1609.74462890625",
         "-70.21217346191406",
         "-1.515618464065227e-10",
         "-70.56536102294922",
         "-9.222221319937773e-10"
        ],
        [
         "8",
         "9",
         "1527.799533420139",
         "1609.7286987304688",
         "-70.20182800292969",
         "-8.36740537968339e-11",
         "-70.56534576416016",
         "-1.539568472708197e-09"
        ],
        [
         "9",
         "10",
         "1627.6031358506943",
         "1609.71826171875",
         "-70.63406372070312",
         "-1.5872374595216066e-11",
         "-70.5653305053711",
         "-7.939728874362117e-10"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>L1Loss</th>\n",
       "      <th>val_L1Loss</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "      <th>val_psnr</th>\n",
       "      <th>val_ssim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1556.951280</td>\n",
       "      <td>1610.125305</td>\n",
       "      <td>-70.284943</td>\n",
       "      <td>9.063277e-10</td>\n",
       "      <td>-70.565842</td>\n",
       "      <td>-8.826771e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1702.884250</td>\n",
       "      <td>1610.080627</td>\n",
       "      <td>-70.887955</td>\n",
       "      <td>-3.853542e-09</td>\n",
       "      <td>-70.565781</td>\n",
       "      <td>-1.012693e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1515.534356</td>\n",
       "      <td>1609.984192</td>\n",
       "      <td>-70.115860</td>\n",
       "      <td>-4.895770e-09</td>\n",
       "      <td>-70.565659</td>\n",
       "      <td>-1.703562e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1559.352539</td>\n",
       "      <td>1609.861084</td>\n",
       "      <td>-70.398109</td>\n",
       "      <td>-3.283771e-09</td>\n",
       "      <td>-70.565506</td>\n",
       "      <td>-1.826288e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1545.541517</td>\n",
       "      <td>1609.824585</td>\n",
       "      <td>-70.343849</td>\n",
       "      <td>-3.253234e-09</td>\n",
       "      <td>-70.565460</td>\n",
       "      <td>-1.882144e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1542.607639</td>\n",
       "      <td>1609.786377</td>\n",
       "      <td>-70.497559</td>\n",
       "      <td>-8.243816e-10</td>\n",
       "      <td>-70.565414</td>\n",
       "      <td>-1.561940e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1501.347873</td>\n",
       "      <td>1609.757874</td>\n",
       "      <td>-69.796379</td>\n",
       "      <td>3.219659e-10</td>\n",
       "      <td>-70.565384</td>\n",
       "      <td>-1.503889e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1526.650323</td>\n",
       "      <td>1609.744629</td>\n",
       "      <td>-70.212173</td>\n",
       "      <td>-1.515618e-10</td>\n",
       "      <td>-70.565361</td>\n",
       "      <td>-9.222221e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1527.799533</td>\n",
       "      <td>1609.728699</td>\n",
       "      <td>-70.201828</td>\n",
       "      <td>-8.367405e-11</td>\n",
       "      <td>-70.565346</td>\n",
       "      <td>-1.539568e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1627.603136</td>\n",
       "      <td>1609.718262</td>\n",
       "      <td>-70.634064</td>\n",
       "      <td>-1.587237e-11</td>\n",
       "      <td>-70.565331</td>\n",
       "      <td>-7.939729e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch       L1Loss   val_L1Loss       psnr          ssim   val_psnr  \\\n",
       "0      1  1556.951280  1610.125305 -70.284943  9.063277e-10 -70.565842   \n",
       "1      2  1702.884250  1610.080627 -70.887955 -3.853542e-09 -70.565781   \n",
       "2      3  1515.534356  1609.984192 -70.115860 -4.895770e-09 -70.565659   \n",
       "3      4  1559.352539  1609.861084 -70.398109 -3.283771e-09 -70.565506   \n",
       "4      5  1545.541517  1609.824585 -70.343849 -3.253234e-09 -70.565460   \n",
       "5      6  1542.607639  1609.786377 -70.497559 -8.243816e-10 -70.565414   \n",
       "6      7  1501.347873  1609.757874 -69.796379  3.219659e-10 -70.565384   \n",
       "7      8  1526.650323  1609.744629 -70.212173 -1.515618e-10 -70.565361   \n",
       "8      9  1527.799533  1609.728699 -70.201828 -8.367405e-11 -70.565346   \n",
       "9     10  1627.603136  1609.718262 -70.634064 -1.587237e-11 -70.565331   \n",
       "\n",
       "       val_ssim  \n",
       "0 -8.826771e-10  \n",
       "1 -1.012693e-09  \n",
       "2 -1.703562e-09  \n",
       "3 -1.826288e-09  \n",
       "4 -1.882144e-09  \n",
       "5 -1.561940e-09  \n",
       "6 -1.503889e-09  \n",
       "7 -9.222221e-10  \n",
       "8 -1.539568e-09  \n",
       "9 -7.939729e-10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(trainer.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with alternative early termination metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early termination at epoch 6 with best validation metric -69.82839965820312\n"
     ]
    }
   ],
   "source": [
    "model = FNet(depth=4)\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=None,\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda',\n",
    "    early_termination_metric = 'psnr' # set early termination metric as psnr for the sake of demonstration\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with mlflow logger callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'lr': 3e-4\n",
    "        },\n",
    "    )\n",
    "\n",
    "del trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=[mlflow_logger_callback],\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wGaN GP example with mlflow logger callback and plot callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNet(\n",
    "    n_channels=1,\n",
    "    n_classes=1\n",
    ")\n",
    "\n",
    "discriminator = GlobalDiscriminator(\n",
    "    n_in_channels = 2,\n",
    "    n_in_filters = 64,\n",
    "    _conv_depth = 4,\n",
    "    _pool_before_fc = True\n",
    ")\n",
    "\n",
    "generator_optimizer = optim.Adam(generator.parameters(), \n",
    "                                 lr=0.0002, \n",
    "                                 betas=(0., 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), \n",
    "                                     lr=0.00002, \n",
    "                                     betas=(0., 0.9),\n",
    "                                     weight_decay=0.001)\n",
    "\n",
    "gp_loss = GradientPenaltyLoss(\n",
    "    _metric_name='gp_loss',\n",
    "    discriminator=discriminator,\n",
    "    weight=10.0,\n",
    ")\n",
    "\n",
    "gen_loss = GeneratorLoss(\n",
    "    _metric_name='gen_loss'\n",
    ")\n",
    "\n",
    "disc_loss = WassersteinLoss(\n",
    "    _metric_name='disc_loss'\n",
    ")\n",
    "\n",
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train_wgan', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'gen_lr': 0.0002,\n",
    "            'disc_lr': 0.00002\n",
    "        },\n",
    "    )\n",
    "\n",
    "plot_callback = IntermediatePlot(\n",
    "    name='plotter',\n",
    "    path=PLOT_DIR,\n",
    "    dataset=ds, # give it the patch dataset as opposed to the cached dataset\n",
    "    indices=[1,3,5,7,9], # plot 5 selected patches images from the dataset\n",
    "    plot_metrics=[SSIM(_metric_name='ssim'), PSNR(_metric_name='psnr')],\n",
    "    figsize=(20, 25),\n",
    "    show_plot=False,\n",
    ")\n",
    "\n",
    "wgan_trainer = WGANTrainer(\n",
    "    dataset=cds,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    patience=20, # setting this to prevent unwanted early termination here\n",
    "    device='cuda',\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gen_optimizer=generator_optimizer,\n",
    "    disc_optimizer=discriminator_optimizer,\n",
    "    generator_loss_fn=gen_loss,\n",
    "    discriminator_loss_fn=disc_loss,\n",
    "    gradient_penalty_fn=gp_loss,\n",
    "    discriminator_update_freq=1,\n",
    "    generator_update_freq=2,\n",
    "    callbacks=[mlflow_logger_callback, plot_callback],\n",
    "    metrics={'ssim': SSIM(_metric_name='ssim'), \n",
    "             'psnr': PSNR(_metric_name='psnr')}\n",
    ")\n",
    "\n",
    "wgan_trainer.train()\n",
    "\n",
    "del generator\n",
    "del wgan_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # wGaN GP example with mlflow logger callback and alternative early termination loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNet(\n",
    "    n_channels=1,\n",
    "    n_classes=1\n",
    ")\n",
    "\n",
    "discriminator = GlobalDiscriminator(\n",
    "    n_in_channels = 2,\n",
    "    n_in_filters = 64,\n",
    "    _conv_depth = 4,\n",
    "    _pool_before_fc = True\n",
    ")\n",
    "\n",
    "generator_optimizer = optim.Adam(generator.parameters(), \n",
    "                                 lr=0.0002, \n",
    "                                 betas=(0., 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), \n",
    "                                     lr=0.00002, \n",
    "                                     betas=(0., 0.9),\n",
    "                                     weight_decay=0.001)\n",
    "\n",
    "gp_loss = GradientPenaltyLoss(\n",
    "    _metric_name='gp_loss',\n",
    "    discriminator=discriminator,\n",
    "    weight=10.0,\n",
    ")\n",
    "\n",
    "gen_loss = GeneratorLoss(\n",
    "    _metric_name='gen_loss'\n",
    ")\n",
    "\n",
    "disc_loss = WassersteinLoss(\n",
    "    _metric_name='disc_loss'\n",
    ")\n",
    "\n",
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train_wgan_mae_early_term', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'gen_lr': 0.0002,\n",
    "            'disc_lr': 0.00002\n",
    "        },\n",
    "    )\n",
    "\n",
    "wgan_trainer = WGANTrainer(\n",
    "    dataset=cds,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    patience=5, # lower patience here\n",
    "    device='cuda',\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gen_optimizer=generator_optimizer,\n",
    "    disc_optimizer=discriminator_optimizer,\n",
    "    generator_loss_fn=gen_loss,\n",
    "    discriminator_loss_fn=disc_loss,\n",
    "    gradient_penalty_fn=gp_loss,\n",
    "    discriminator_update_freq=1,\n",
    "    generator_update_freq=2,\n",
    "    callbacks=[mlflow_logger_callback],\n",
    "    metrics={'ssim': SSIM(_metric_name='ssim'), \n",
    "             'psnr': PSNR(_metric_name='psnr'),\n",
    "             'mae': MetricsWrapper(_metric_name='mae', module=nn.L1Loss()) # use a wrapper for torch nn L1Loss\n",
    "             },\n",
    "    early_termination_metric = 'mae' # update early temrination loss with the supplied L1Loss/mae metric instead of the default GaN generator loss\n",
    ")\n",
    "\n",
    "wgan_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_gan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
