{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A minimal example to demonstrate how the trainer for FNet and wGaN GP plus the callbacks works along with patched dataset\n",
    "\n",
    "Is dependent on the files produced by 1.illumination_correction/0.create_loaddata_csvs ALSF pilot data repo https://github.com/WayScience/pediatric_cancer_atlas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weishanli/Waylab\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append(str(pathlib.Path('.').absolute().parent.parent))\n",
    "print(str(pathlib.Path('.').absolute().parent.parent))\n",
    "\n",
    "## Dataset\n",
    "from virtual_stain_flow.datasets.PatchDataset import PatchDataset\n",
    "from virtual_stain_flow.datasets.CachedDataset import CachedDataset\n",
    "\n",
    "## FNet training\n",
    "from virtual_stain_flow.models.fnet import FNet\n",
    "from virtual_stain_flow.trainers.Trainer import Trainer\n",
    "\n",
    "## wGaN training\n",
    "from virtual_stain_flow.models.unet import UNet\n",
    "from virtual_stain_flow.models.discriminator import GlobalDiscriminator\n",
    "from virtual_stain_flow.trainers.WGaNTrainer import WGaNTrainer\n",
    "\n",
    "## wGaN losses\n",
    "from virtual_stain_flow.losses.GradientPenaltyLoss import GradientPenaltyLoss\n",
    "from virtual_stain_flow.losses.DiscriminatorLoss import DiscriminatorLoss\n",
    "from virtual_stain_flow.losses.GeneratorLoss import GeneratorLoss\n",
    "\n",
    "from virtual_stain_flow.transforms.MinMaxNormalize import MinMaxNormalize\n",
    "\n",
    "## Metrics\n",
    "from virtual_stain_flow.metrics.MetricsWrapper import MetricsWrapper\n",
    "from virtual_stain_flow.metrics.PSNR import PSNR\n",
    "from virtual_stain_flow.metrics.SSIM import SSIM\n",
    "\n",
    "## callback\n",
    "from virtual_stain_flow.callbacks.MlflowLogger import MlflowLogger\n",
    "from virtual_stain_flow.callbacks.IntermediatePlot import IntermediatePatchPlot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify train output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_DIR = pathlib.Path('.').absolute() / 'example_train'\n",
    "EXAMPLE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf example_train/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = EXAMPLE_DIR / 'plot'\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MLFLOW_DIR =EXAMPLE_DIR / 'mlflow'\n",
    "MLFLOW_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify paths to loaddata and read a single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REPLACE WITH YOUR OWN PATHS\n",
    "analysis_home_path = pathlib.Path('/home/weishanli/Waylab/ALSF_pilot/ALSF_img2img_prototyping')\n",
    "sc_features_parquet_path = pathlib.Path(\n",
    "    '/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pilot_data/preprocessed_profiles_SN0313537/single_cell_profiles'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            FileName_OrigBrightfield  \\\n",
      "2079  r06c22f01p01-ch1sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch1sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch1sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch1sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch1sk1fk1fl1.tiff   \n",
      "\n",
      "                               PathName_OrigBrightfield  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "\n",
      "                     FileName_OrigER  \\\n",
      "2079  r06c22f01p01-ch2sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch2sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch2sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch2sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch2sk1fk1fl1.tiff   \n",
      "\n",
      "                                        PathName_OrigER  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "\n",
      "                    FileName_OrigAGP  \\\n",
      "2079  r06c22f01p01-ch3sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch3sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch3sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch3sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch3sk1fk1fl1.tiff   \n",
      "\n",
      "                                       PathName_OrigAGP  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "\n",
      "                   FileName_OrigMito  \\\n",
      "2079  r06c22f01p01-ch4sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch4sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch4sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch4sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch4sk1fk1fl1.tiff   \n",
      "\n",
      "                                      PathName_OrigMito  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "\n",
      "                    FileName_OrigDNA  \\\n",
      "2079  r06c22f01p01-ch5sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch5sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch5sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch5sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch5sk1fk1fl1.tiff   \n",
      "\n",
      "                                       PathName_OrigDNA  ...  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "\n",
      "     Metadata_AbsPositionZ Metadata_ChannelID Metadata_Col Metadata_FieldID  \\\n",
      "2079              0.134358                  6           22                1   \n",
      "668               0.134405                  6            9                3   \n",
      "2073              0.134366                  6           22                4   \n",
      "1113              0.134347                  6           13                7   \n",
      "788               0.134381                  6           10                6   \n",
      "\n",
      "      Metadata_PlaneID  Metadata_PositionX  Metadata_PositionY  \\\n",
      "2079                 1            0.000000            0.000000   \n",
      "668                  1            0.000000            0.000646   \n",
      "2073                 1            0.000646            0.000646   \n",
      "1113                 1           -0.000646           -0.000646   \n",
      "788                  1           -0.000646            0.000000   \n",
      "\n",
      "      Metadata_PositionZ  Metadata_Row  Metadata_Reimaged  \n",
      "2079           -0.000006             6              False  \n",
      "668            -0.000006             5              False  \n",
      "2073           -0.000006             5              False  \n",
      "1113           -0.000006             6              False  \n",
      "788            -0.000006             6              False  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "  Metadata_Plate Metadata_Well  Metadata_Site  \\\n",
      "0     BR00143976           C03              2   \n",
      "1     BR00143976           C03              6   \n",
      "2     BR00143976           C03              9   \n",
      "3     BR00143976           C03              5   \n",
      "4     BR00143976           C03              7   \n",
      "\n",
      "   Metadata_Cells_Location_Center_X  Metadata_Cells_Location_Center_Y  \n",
      "0                        629.552987                         62.017799  \n",
      "1                        279.951864                         56.588228  \n",
      "2                        876.508878                        205.794360  \n",
      "3                        479.254866                         45.496581  \n",
      "4                        866.557068                        205.908787  \n"
     ]
    }
   ],
   "source": [
    "loaddata_csv_path = analysis_home_path \\\n",
    "    / '0.data_analysis_and_preprocessing' / 'loaddata_csvs'\n",
    "\n",
    "if loaddata_csv_path.exists():\n",
    "    try:\n",
    "        loaddata_csv = next(loaddata_csv_path.glob('*.csv'))\n",
    "    except:\n",
    "        raise FileNotFoundError(\"No loaddata csv found\")\n",
    "else:\n",
    "    raise ValueError(\"Incorrect loaddata csv path\")\n",
    "\n",
    "loaddata_df = pd.read_csv(loaddata_csv)\n",
    "# subsample to reduce runtime\n",
    "loaddata_df = loaddata_df.sample(n=100, random_state=42)\n",
    "\n",
    "sc_features = pd.DataFrame()\n",
    "for plate in loaddata_df['Metadata_Plate'].unique():\n",
    "    sc_features_parquet = sc_features_parquet_path / f'{plate}_sc_normalized.parquet'\n",
    "    if not sc_features_parquet.exists():\n",
    "        print(f'{sc_features_parquet} does not exist, skipping...')\n",
    "        continue \n",
    "    else:\n",
    "        sc_features = pd.concat([\n",
    "            sc_features, \n",
    "            pd.read_parquet(\n",
    "                sc_features_parquet,\n",
    "                columns=['Metadata_Plate', 'Metadata_Well', 'Metadata_Site', 'Metadata_Cells_Location_Center_X', 'Metadata_Cells_Location_Center_Y']\n",
    "            )\n",
    "        ])\n",
    "\n",
    "print(loaddata_df.head())\n",
    "print(sc_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Patch size and channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "\n",
    "channel_names = [\n",
    "    \"OrigBrightfield\",\n",
    "    \"OrigDNA\",\n",
    "    \"OrigER\",\n",
    "    \"OrigMito\",\n",
    "    \"OrigRNA\",\n",
    "    \"OrigAGP\",\n",
    "]\n",
    "input_channel_name = \"OrigBrightfield\"\n",
    "target_channel_names = [ch for ch in channel_names if ch != input_channel_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Patch dataset and Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-20 10:22:43,813 - DEBUG - Dataframe supplied for loaddata_csv, using as is\n",
      "2025-02-20 10:22:43,813 - DEBUG - Dataframe supplied for sc_feature, using as is\n",
      "2025-02-20 10:22:43,813 - DEBUG - X and Y columns Metadata_Cells_Location_Center_X, Metadata_Cells_Location_Center_Y detected in sc_feature dataframe, using as the coordinates for cell centers\n",
      "2025-02-20 10:22:43,813 - DEBUG - Both loaddata_csv and sc_feature supplied, inferring merge fields to associate the two dataframes\n",
      "2025-02-20 10:22:43,813 - DEBUG - Merge fields inferred: ['Metadata_Site', 'Metadata_Well', 'Metadata_Plate']\n",
      "2025-02-20 10:22:43,813 - DEBUG - Dataframe supplied for sc_feature, using as is\n",
      "2025-02-20 10:22:43,850 - DEBUG - Inferring channel keys from loaddata csv\n",
      "2025-02-20 10:22:43,851 - DEBUG - Channel keys: {'OrigER', 'OrigMito', 'OrigBrightfield', 'OrigRNA', 'OrigDNA', 'OrigAGP'} inferred from loaddata csv\n",
      "2025-02-20 10:22:43,851 - DEBUG - Setting input channel(s) ...\n",
      "2025-02-20 10:22:43,851 - DEBUG - No channel keys specified, skip\n",
      "2025-02-20 10:22:43,851 - DEBUG - Setting target channel(s) ...\n",
      "2025-02-20 10:22:43,851 - DEBUG - No channel keys specified, skip\n",
      "2025-02-20 10:22:43,851 - DEBUG - Setting input transform ...\n",
      "2025-02-20 10:22:43,851 - DEBUG - Setting target transform ...\n",
      "2025-02-20 10:22:43,851 - DEBUG - Extracting image channel paths of site/view and associatedcell coordinates (if applicable) from loaddata csv\n",
      "2025-02-20 10:22:43,875 - DEBUG - Extracted images of all input and target channels for 93 unique sites/view and 10090 cells\n",
      "2025-02-20 10:22:43,875 - DEBUG - Generating patches that contain cells\n",
      "2025-02-20 10:22:43,899 - DEBUG - Image size inferred: 1080 for all images to force redetect image sizes for each view/site set consistent_img_size=False\n",
      "2025-02-20 10:22:44,318 - DEBUG - Generated 461 patches for 93 site/view\n",
      "2025-02-20 10:22:44,319 - DEBUG - Set input channel(s) as ['OrigBrightfield']\n",
      "2025-02-20 10:22:44,319 - DEBUG - Set target channel(s) as ['OrigDNA']\n"
     ]
    }
   ],
   "source": [
    "pds = PatchDataset(\n",
    "    _loaddata_csv=loaddata_df,\n",
    "    _sc_feature=sc_features,\n",
    "    _input_channel_keys=None,\n",
    "    _target_channel_keys=None,\n",
    "    _input_transform=MinMaxNormalize(_normalization_factor=(2 ** 16) - 1, _always_apply=True),\n",
    "    _target_transform=MinMaxNormalize(_normalization_factor=(2 ** 16) - 1, _always_apply=True),\n",
    "    patch_size=PATCH_SIZE,\n",
    "    verbose=True,\n",
    "    patch_generation_method=\"random_cell\",\n",
    "    patch_generation_random_seed=42\n",
    ")\n",
    "\n",
    "## Set input and target channels\n",
    "pds.set_input_channel_keys([input_channel_name])\n",
    "pds.set_target_channel_keys('OrigDNA')\n",
    "\n",
    "## Cache for faster training \n",
    "cds = CachedDataset(\n",
    "    pds,\n",
    "    prefill_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNet trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model without callback and check logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNet(depth=4)\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=None,\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>L1Loss</th>\n",
       "      <th>val_L1Loss</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "      <th>val_psnr</th>\n",
       "      <th>val_ssim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.478871</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>6.329101</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>6.742533</td>\n",
       "      <td>0.032114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.428279</td>\n",
       "      <td>0.438360</td>\n",
       "      <td>7.297186</td>\n",
       "      <td>0.043409</td>\n",
       "      <td>7.122532</td>\n",
       "      <td>0.033492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.382448</td>\n",
       "      <td>0.412966</td>\n",
       "      <td>8.268170</td>\n",
       "      <td>0.043539</td>\n",
       "      <td>7.640979</td>\n",
       "      <td>0.035500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.343706</td>\n",
       "      <td>0.396219</td>\n",
       "      <td>9.204294</td>\n",
       "      <td>0.046435</td>\n",
       "      <td>8.010185</td>\n",
       "      <td>0.038775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.294751</td>\n",
       "      <td>0.368890</td>\n",
       "      <td>10.388447</td>\n",
       "      <td>0.056670</td>\n",
       "      <td>8.629682</td>\n",
       "      <td>0.039226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.259627</td>\n",
       "      <td>0.291441</td>\n",
       "      <td>11.531624</td>\n",
       "      <td>0.062310</td>\n",
       "      <td>10.704532</td>\n",
       "      <td>0.037991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.227637</td>\n",
       "      <td>0.246790</td>\n",
       "      <td>12.642867</td>\n",
       "      <td>0.074122</td>\n",
       "      <td>12.188992</td>\n",
       "      <td>0.058526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.199925</td>\n",
       "      <td>0.207696</td>\n",
       "      <td>13.745816</td>\n",
       "      <td>0.075425</td>\n",
       "      <td>13.466536</td>\n",
       "      <td>0.055031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.164005</td>\n",
       "      <td>0.157645</td>\n",
       "      <td>15.256923</td>\n",
       "      <td>0.090092</td>\n",
       "      <td>15.916401</td>\n",
       "      <td>0.080869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.141493</td>\n",
       "      <td>0.142309</td>\n",
       "      <td>16.464945</td>\n",
       "      <td>0.103618</td>\n",
       "      <td>16.622252</td>\n",
       "      <td>0.086847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    L1Loss  val_L1Loss       psnr      ssim   val_psnr  val_ssim\n",
       "0      1  0.478871    0.458065   6.329101  0.028812   6.742533  0.032114\n",
       "1      2  0.428279    0.438360   7.297186  0.043409   7.122532  0.033492\n",
       "2      3  0.382448    0.412966   8.268170  0.043539   7.640979  0.035500\n",
       "3      4  0.343706    0.396219   9.204294  0.046435   8.010185  0.038775\n",
       "4      5  0.294751    0.368890  10.388447  0.056670   8.629682  0.039226\n",
       "5      6  0.259627    0.291441  11.531624  0.062310  10.704532  0.037991\n",
       "6      7  0.227637    0.246790  12.642867  0.074122  12.188992  0.058526\n",
       "7      8  0.199925    0.207696  13.745816  0.075425  13.466536  0.055031\n",
       "8      9  0.164005    0.157645  15.256923  0.090092  15.916401  0.080869\n",
       "9     10  0.141493    0.142309  16.464945  0.103618  16.622252  0.086847"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(trainer.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with alternative early termination metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early termination at epoch 6 with best validation metric 6.6218791007995605\n"
     ]
    }
   ],
   "source": [
    "model = FNet(depth=4)\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=None,\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda',\n",
    "    early_termination_metric = 'psnr' # set early termination metric as psnr for the sake of demonstration\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with mlflow logger callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'lr': 3e-4\n",
    "        },\n",
    "    )\n",
    "\n",
    "del trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=[mlflow_logger_callback],\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wGaN GP example with mlflow logger callback and plot callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNet(\n",
    "    n_channels=1,\n",
    "    n_classes=1\n",
    ")\n",
    "\n",
    "discriminator = GlobalDiscriminator(\n",
    "    n_in_channels = 2,\n",
    "    n_in_filters = 64,\n",
    "    _conv_depth = 4,\n",
    "    _pool_before_fc = True\n",
    ")\n",
    "\n",
    "generator_optimizer = optim.Adam(generator.parameters(), \n",
    "                                 lr=0.0002, \n",
    "                                 betas=(0., 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), \n",
    "                                     lr=0.00002, \n",
    "                                     betas=(0., 0.9),\n",
    "                                     weight_decay=0.001)\n",
    "\n",
    "gp_loss = GradientPenaltyLoss(\n",
    "    _metric_name='gp_loss',\n",
    "    discriminator=discriminator,\n",
    "    weight=10.0,\n",
    ")\n",
    "\n",
    "gen_loss = GeneratorLoss(\n",
    "    _metric_name='gen_loss'\n",
    ")\n",
    "\n",
    "disc_loss = DiscriminatorLoss(\n",
    "    _metric_name='disc_loss'\n",
    ")\n",
    "\n",
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train_wgan', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'gen_lr': 0.0002,\n",
    "            'disc_lr': 0.00002\n",
    "        },\n",
    "    )\n",
    "\n",
    "plot_callback = IntermediatePatchPlot(\n",
    "    name='plotter',\n",
    "    path=PLOT_DIR,\n",
    "    dataset=pds, # give it the patch dataset as opposed to the cached dataset\n",
    "    plot_metrics=[SSIM(_metric_name='ssim'), PSNR(_metric_name='psnr')],\n",
    "    figsize=(20, 25),\n",
    "    show_plot=False,\n",
    ")\n",
    "\n",
    "wgan_trainer = WGaNTrainer(\n",
    "    dataset=cds,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    patience=20, # setting this to prevent unwanted early termination here\n",
    "    device='cuda',\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gen_optimizer=generator_optimizer,\n",
    "    disc_optimizer=discriminator_optimizer,\n",
    "    generator_loss_fn=gen_loss,\n",
    "    discriminator_loss_fn=disc_loss,\n",
    "    gradient_penalty_fn=gp_loss,\n",
    "    discriminator_update_freq=1,\n",
    "    generator_update_freq=2,\n",
    "    callbacks=[mlflow_logger_callback, plot_callback],\n",
    "    metrics={'ssim': SSIM(_metric_name='ssim'), \n",
    "             'psnr': PSNR(_metric_name='psnr')},\n",
    ")\n",
    "\n",
    "wgan_trainer.train()\n",
    "\n",
    "del generator\n",
    "del wgan_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # wGaN GP example with mlflow logger callback and alternative early termination loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNet(\n",
    "    n_channels=1,\n",
    "    n_classes=1\n",
    ")\n",
    "\n",
    "discriminator = GlobalDiscriminator(\n",
    "    n_in_channels = 2,\n",
    "    n_in_filters = 64,\n",
    "    _conv_depth = 4,\n",
    "    _pool_before_fc = True\n",
    ")\n",
    "\n",
    "generator_optimizer = optim.Adam(generator.parameters(), \n",
    "                                 lr=0.0002, \n",
    "                                 betas=(0., 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), \n",
    "                                     lr=0.00002, \n",
    "                                     betas=(0., 0.9),\n",
    "                                     weight_decay=0.001)\n",
    "\n",
    "gp_loss = GradientPenaltyLoss(\n",
    "    _metric_name='gp_loss',\n",
    "    discriminator=discriminator,\n",
    "    weight=10.0,\n",
    ")\n",
    "\n",
    "gen_loss = GeneratorLoss(\n",
    "    _metric_name='gen_loss'\n",
    ")\n",
    "\n",
    "disc_loss = DiscriminatorLoss(\n",
    "    _metric_name='disc_loss'\n",
    ")\n",
    "\n",
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train_wgan_mae_early_term', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'gen_lr': 0.0002,\n",
    "            'disc_lr': 0.00002\n",
    "        },\n",
    "    )\n",
    "\n",
    "wgan_trainer = WGaNTrainer(\n",
    "    dataset=cds,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    patience=5, # lower patience here\n",
    "    device='cuda',\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gen_optimizer=generator_optimizer,\n",
    "    disc_optimizer=discriminator_optimizer,\n",
    "    generator_loss_fn=gen_loss,\n",
    "    discriminator_loss_fn=disc_loss,\n",
    "    gradient_penalty_fn=gp_loss,\n",
    "    discriminator_update_freq=1,\n",
    "    generator_update_freq=2,\n",
    "    callbacks=[mlflow_logger_callback],\n",
    "    metrics={'ssim': SSIM(_metric_name='ssim'), \n",
    "             'psnr': PSNR(_metric_name='psnr'),\n",
    "             'mae': MetricsWrapper(_metric_name='mae', module=nn.L1Loss()) # use a wrapper for torch nn L1Loss\n",
    "             },\n",
    "    early_termination_metric = 'mae' # update early temrination loss with the supplied L1Loss/mae metric instead of the default GaN generator loss\n",
    ")\n",
    "\n",
    "wgan_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp_gan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
