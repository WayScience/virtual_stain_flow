{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A minimal example to demonstrate how the trainer for FNet and wGaN GP plus the callbacks works along with patched dataset\n",
    "\n",
    "Is dependent on the files produced by 1.illumination_correction/0.create_loaddata_csvs ALSF pilot data repo https://github.com/WayScience/pediatric_cancer_atlas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/weishanli/Waylab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/weishanli/anaconda3/envs/speckle_analysis/lib/python3.11/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.4' (you have '2.0.1'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "sys.path.append(str(pathlib.Path('.').absolute().parent.parent))\n",
    "print(str(pathlib.Path('.').absolute().parent.parent))\n",
    "\n",
    "## Dataset\n",
    "from virtual_stain_flow.datasets.PatchDataset import PatchDataset\n",
    "from virtual_stain_flow.datasets.CachedDataset import CachedDataset\n",
    "\n",
    "## FNet training\n",
    "from virtual_stain_flow.models.fnet import FNet\n",
    "from virtual_stain_flow.trainers.Trainer import Trainer\n",
    "\n",
    "## wGaN training\n",
    "from virtual_stain_flow.models.unet import UNet\n",
    "from virtual_stain_flow.models.discriminator import GlobalDiscriminator\n",
    "from virtual_stain_flow.trainers.WGaNTrainer import WGaNTrainer\n",
    "\n",
    "## wGaN losses\n",
    "from virtual_stain_flow.losses.GradientPenaltyLoss import GradientPenaltyLoss\n",
    "from virtual_stain_flow.losses.DiscriminatorLoss import DiscriminatorLoss\n",
    "from virtual_stain_flow.losses.GeneratorLoss import GeneratorLoss\n",
    "\n",
    "from virtual_stain_flow.transforms.MinMaxNormalize import MinMaxNormalize\n",
    "\n",
    "## Metrics\n",
    "from virtual_stain_flow.metrics.MetricsWrapper import MetricsWrapper\n",
    "from virtual_stain_flow.metrics.PSNR import PSNR\n",
    "from virtual_stain_flow.metrics.SSIM import SSIM\n",
    "\n",
    "## callback\n",
    "from virtual_stain_flow.callbacks.MlflowLogger import MlflowLogger\n",
    "from virtual_stain_flow.callbacks.IntermediatePlot import IntermediatePatchPlot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify train output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_DIR = pathlib.Path('.').absolute() / 'example_train'\n",
    "EXAMPLE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf example_train/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_DIR = EXAMPLE_DIR / 'plot'\n",
    "PLOT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MLFLOW_DIR =EXAMPLE_DIR / 'mlflow'\n",
    "MLFLOW_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify paths to loaddata and read a single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REPLACE WITH YOUR OWN PATHS\n",
    "analysis_home_path = pathlib.Path('/home/weishanli/Waylab/ALSF_pilot/ALSF_img2img_prototyping')\n",
    "sc_features_parquet_path = pathlib.Path(\n",
    "    '/home/weishanli/Waylab/ALSF_pilot/data/ALSF_pilot_data/preprocessed_profiles_SN0313537/single_cell_profiles'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            FileName_OrigBrightfield  \\\n",
      "2079  r06c22f01p01-ch1sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch1sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch1sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch1sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch1sk1fk1fl1.tiff   \n",
      "\n",
      "                               PathName_OrigBrightfield  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "\n",
      "                     FileName_OrigER  \\\n",
      "2079  r06c22f01p01-ch2sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch2sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch2sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch2sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch2sk1fk1fl1.tiff   \n",
      "\n",
      "                                        PathName_OrigER  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "\n",
      "                    FileName_OrigAGP  \\\n",
      "2079  r06c22f01p01-ch3sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch3sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch3sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch3sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch3sk1fk1fl1.tiff   \n",
      "\n",
      "                                       PathName_OrigAGP  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "\n",
      "                   FileName_OrigMito  \\\n",
      "2079  r06c22f01p01-ch4sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch4sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch4sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch4sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch4sk1fk1fl1.tiff   \n",
      "\n",
      "                                      PathName_OrigMito  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...   \n",
      "\n",
      "                    FileName_OrigDNA  \\\n",
      "2079  r06c22f01p01-ch5sk1fk1fl1.tiff   \n",
      "668   r05c09f03p01-ch5sk1fk1fl1.tiff   \n",
      "2073  r05c22f04p01-ch5sk1fk1fl1.tiff   \n",
      "1113  r06c13f07p01-ch5sk1fk1fl1.tiff   \n",
      "788   r06c10f06p01-ch5sk1fk1fl1.tiff   \n",
      "\n",
      "                                       PathName_OrigDNA  ...  \\\n",
      "2079  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "668   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "2073  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "1113  /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "788   /home/weishanli/Waylab/ALSF_pilot/data/ALSF_pi...  ...   \n",
      "\n",
      "     Metadata_AbsPositionZ Metadata_ChannelID Metadata_Col Metadata_FieldID  \\\n",
      "2079              0.134358                  6           22                1   \n",
      "668               0.134405                  6            9                3   \n",
      "2073              0.134366                  6           22                4   \n",
      "1113              0.134347                  6           13                7   \n",
      "788               0.134381                  6           10                6   \n",
      "\n",
      "      Metadata_PlaneID  Metadata_PositionX  Metadata_PositionY  \\\n",
      "2079                 1            0.000000            0.000000   \n",
      "668                  1            0.000000            0.000646   \n",
      "2073                 1            0.000646            0.000646   \n",
      "1113                 1           -0.000646           -0.000646   \n",
      "788                  1           -0.000646            0.000000   \n",
      "\n",
      "      Metadata_PositionZ  Metadata_Row  Metadata_Reimaged  \n",
      "2079           -0.000006             6              False  \n",
      "668            -0.000006             5              False  \n",
      "2073           -0.000006             5              False  \n",
      "1113           -0.000006             6              False  \n",
      "788            -0.000006             6              False  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "  Metadata_Plate Metadata_Well  Metadata_Site  \\\n",
      "0     BR00143976           C03              2   \n",
      "1     BR00143976           C03              6   \n",
      "2     BR00143976           C03              9   \n",
      "3     BR00143976           C03              5   \n",
      "4     BR00143976           C03              7   \n",
      "\n",
      "   Metadata_Cells_Location_Center_X  Metadata_Cells_Location_Center_Y  \n",
      "0                        629.552987                         62.017799  \n",
      "1                        279.951864                         56.588228  \n",
      "2                        876.508878                        205.794360  \n",
      "3                        479.254866                         45.496581  \n",
      "4                        866.557068                        205.908787  \n"
     ]
    }
   ],
   "source": [
    "loaddata_csv_path = analysis_home_path \\\n",
    "    / '0.data_analysis_and_preprocessing' / 'loaddata_csvs'\n",
    "\n",
    "if loaddata_csv_path.exists():\n",
    "    try:\n",
    "        loaddata_csv = next(loaddata_csv_path.glob('*.csv'))\n",
    "    except:\n",
    "        raise FileNotFoundError(\"No loaddata csv found\")\n",
    "else:\n",
    "    raise ValueError(\"Incorrect loaddata csv path\")\n",
    "\n",
    "loaddata_df = pd.read_csv(loaddata_csv)\n",
    "# subsample to reduce runtime\n",
    "loaddata_df = loaddata_df.sample(n=100, random_state=42)\n",
    "\n",
    "sc_features = pd.DataFrame()\n",
    "for plate in loaddata_df['Metadata_Plate'].unique():\n",
    "    sc_features_parquet = sc_features_parquet_path / f'{plate}_sc_normalized.parquet'\n",
    "    if not sc_features_parquet.exists():\n",
    "        print(f'{sc_features_parquet} does not exist, skipping...')\n",
    "        continue \n",
    "    else:\n",
    "        sc_features = pd.concat([\n",
    "            sc_features, \n",
    "            pd.read_parquet(\n",
    "                sc_features_parquet,\n",
    "                columns=['Metadata_Plate', 'Metadata_Well', 'Metadata_Site', 'Metadata_Cells_Location_Center_X', 'Metadata_Cells_Location_Center_Y']\n",
    "            )\n",
    "        ])\n",
    "\n",
    "print(loaddata_df.head())\n",
    "print(sc_features.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure Patch size and channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATCH_SIZE = 256\n",
    "\n",
    "channel_names = [\n",
    "    \"OrigBrightfield\",\n",
    "    \"OrigDNA\",\n",
    "    \"OrigER\",\n",
    "    \"OrigMito\",\n",
    "    \"OrigRNA\",\n",
    "    \"OrigAGP\",\n",
    "]\n",
    "input_channel_name = \"OrigBrightfield\"\n",
    "target_channel_names = [ch for ch in channel_names if ch != input_channel_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Patch dataset and Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 10:15:52,796 - DEBUG - Dataframe supplied for loaddata_csv, using as is\n",
      "2025-02-18 10:15:52,797 - DEBUG - Dataframe supplied for sc_feature, using as is\n",
      "2025-02-18 10:15:52,797 - DEBUG - X and Y columns Metadata_Cells_Location_Center_X, Metadata_Cells_Location_Center_Y detected in sc_feature dataframe, using as the coordinates for cell centers\n",
      "2025-02-18 10:15:52,797 - DEBUG - Both loaddata_csv and sc_feature supplied, inferring merge fields to associate the two dataframes\n",
      "2025-02-18 10:15:52,797 - DEBUG - Merge fields inferred: ['Metadata_Plate', 'Metadata_Site', 'Metadata_Well']\n",
      "2025-02-18 10:15:52,797 - DEBUG - Dataframe supplied for sc_feature, using as is\n",
      "2025-02-18 10:15:52,820 - DEBUG - Inferring channel keys from loaddata csv\n",
      "2025-02-18 10:15:52,820 - DEBUG - Channel keys: {'OrigMito', 'OrigRNA', 'OrigDNA', 'OrigAGP', 'OrigER', 'OrigBrightfield'} inferred from loaddata csv\n",
      "2025-02-18 10:15:52,820 - DEBUG - Setting input channel(s) ...\n",
      "2025-02-18 10:15:52,821 - DEBUG - No channel keys specified, skip\n",
      "2025-02-18 10:15:52,821 - DEBUG - Setting target channel(s) ...\n",
      "2025-02-18 10:15:52,821 - DEBUG - No channel keys specified, skip\n",
      "2025-02-18 10:15:52,821 - DEBUG - Setting input transform ...\n",
      "2025-02-18 10:15:52,822 - DEBUG - Setting target transform ...\n",
      "2025-02-18 10:15:52,822 - DEBUG - Extracting image channel paths of site/view and associatedcell coordinates (if applicable) from loaddata csv\n",
      "2025-02-18 10:15:52,840 - DEBUG - Extracted images of all input and target channels for 93 unique sites/view and 10090 cells\n",
      "2025-02-18 10:15:52,840 - DEBUG - Generating patches that contain cells\n",
      "2025-02-18 10:15:52,858 - DEBUG - Image size inferred: 1080 for all images to force redetect image sizes for each view/site set consistent_img_size=False\n",
      "2025-02-18 10:15:53,246 - DEBUG - Generated 461 patches for 93 site/view\n",
      "2025-02-18 10:15:53,246 - DEBUG - Set input channel(s) as ['OrigBrightfield']\n",
      "2025-02-18 10:15:53,246 - DEBUG - Set target channel(s) as ['OrigDNA']\n"
     ]
    }
   ],
   "source": [
    "pds = PatchDataset(\n",
    "    _loaddata_csv=loaddata_df,\n",
    "    _sc_feature=sc_features,\n",
    "    _input_channel_keys=None,\n",
    "    _target_channel_keys=None,\n",
    "    _input_transform=MinMaxNormalize(_normalization_factor=(2 ** 16) - 1, _always_apply=True),\n",
    "    _target_transform=MinMaxNormalize(_normalization_factor=(2 ** 16) - 1, _always_apply=True),\n",
    "    patch_size=PATCH_SIZE,\n",
    "    verbose=True,\n",
    "    patch_generation_method=\"random_cell\",\n",
    "    patch_generation_random_seed=42\n",
    ")\n",
    "\n",
    "## Set input and target channels\n",
    "pds.set_input_channel_keys([input_channel_name])\n",
    "pds.set_target_channel_keys('OrigDNA')\n",
    "\n",
    "## Cache for faster training \n",
    "cds = CachedDataset(\n",
    "    pds,\n",
    "    prefill_cache=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNet trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model without callback and check logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNet(depth=4)\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=None,\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>L1Loss</th>\n",
       "      <th>val_L1Loss</th>\n",
       "      <th>psnr</th>\n",
       "      <th>ssim</th>\n",
       "      <th>val_psnr</th>\n",
       "      <th>val_ssim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.456883</td>\n",
       "      <td>0.474489</td>\n",
       "      <td>6.632703</td>\n",
       "      <td>0.018613</td>\n",
       "      <td>6.418595</td>\n",
       "      <td>0.026234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.400776</td>\n",
       "      <td>0.453664</td>\n",
       "      <td>7.765750</td>\n",
       "      <td>0.025268</td>\n",
       "      <td>6.804714</td>\n",
       "      <td>0.027302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.358529</td>\n",
       "      <td>0.414073</td>\n",
       "      <td>8.702980</td>\n",
       "      <td>0.024505</td>\n",
       "      <td>7.590396</td>\n",
       "      <td>0.029586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.304907</td>\n",
       "      <td>0.343430</td>\n",
       "      <td>10.004862</td>\n",
       "      <td>0.034862</td>\n",
       "      <td>9.206196</td>\n",
       "      <td>0.034965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.272098</td>\n",
       "      <td>0.276465</td>\n",
       "      <td>10.939101</td>\n",
       "      <td>0.042278</td>\n",
       "      <td>11.154539</td>\n",
       "      <td>0.041764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.232606</td>\n",
       "      <td>0.226715</td>\n",
       "      <td>12.247836</td>\n",
       "      <td>0.047612</td>\n",
       "      <td>12.796427</td>\n",
       "      <td>0.051223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.192591</td>\n",
       "      <td>0.203203</td>\n",
       "      <td>13.729950</td>\n",
       "      <td>0.087152</td>\n",
       "      <td>13.635719</td>\n",
       "      <td>0.051709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.165829</td>\n",
       "      <td>0.173625</td>\n",
       "      <td>15.012578</td>\n",
       "      <td>0.091547</td>\n",
       "      <td>14.903670</td>\n",
       "      <td>0.072398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.141518</td>\n",
       "      <td>0.136609</td>\n",
       "      <td>16.231110</td>\n",
       "      <td>0.093675</td>\n",
       "      <td>16.804295</td>\n",
       "      <td>0.080310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.122126</td>\n",
       "      <td>0.129176</td>\n",
       "      <td>17.322950</td>\n",
       "      <td>0.115414</td>\n",
       "      <td>17.221750</td>\n",
       "      <td>0.093323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch    L1Loss  val_L1Loss       psnr      ssim   val_psnr  val_ssim\n",
       "0      1  0.456883    0.474489   6.632703  0.018613   6.418595  0.026234\n",
       "1      2  0.400776    0.453664   7.765750  0.025268   6.804714  0.027302\n",
       "2      3  0.358529    0.414073   8.702980  0.024505   7.590396  0.029586\n",
       "3      4  0.304907    0.343430  10.004862  0.034862   9.206196  0.034965\n",
       "4      5  0.272098    0.276465  10.939101  0.042278  11.154539  0.041764\n",
       "5      6  0.232606    0.226715  12.247836  0.047612  12.796427  0.051223\n",
       "6      7  0.192591    0.203203  13.729950  0.087152  13.635719  0.051709\n",
       "7      8  0.165829    0.173625  15.012578  0.091547  14.903670  0.072398\n",
       "8      9  0.141518    0.136609  16.231110  0.093675  16.804295  0.080310\n",
       "9     10  0.122126    0.129176  17.322950  0.115414  17.221750  0.093323"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(trainer.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model with alternative early termination metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early termination at epoch 6 with best validation metric 6.414916038513184\n"
     ]
    }
   ],
   "source": [
    "model = FNet(depth=4)\n",
    "lr = 3e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=None,\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda',\n",
    "    early_termination_metric = 'psnr' # set early termination metric as psnr for the sake of demonstration\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with mlflow logger callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'lr': 3e-4\n",
    "        },\n",
    "    )\n",
    "\n",
    "del trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    backprop_loss = nn.L1Loss(),\n",
    "    dataset = cds,\n",
    "    batch_size = 16,\n",
    "    epochs = 10,\n",
    "    patience = 5,\n",
    "    callbacks=[mlflow_logger_callback],\n",
    "    metrics={'psnr': PSNR(_metric_name=\"psnr\"), 'ssim': SSIM(_metric_name=\"ssim\")},\n",
    "    device = 'cuda'\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wGaN GP example with mlflow logger callback and plot callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = UNet(\n",
    "    n_channels=1,\n",
    "    n_classes=1\n",
    ")\n",
    "\n",
    "discriminator = GlobalDiscriminator(\n",
    "    n_in_channels = 2,\n",
    "    n_in_filters = 64,\n",
    "    _conv_depth = 4,\n",
    "    _pool_before_fc = True\n",
    ")\n",
    "\n",
    "generator_optimizer = optim.Adam(generator.parameters(), \n",
    "                                 lr=0.0002, \n",
    "                                 betas=(0., 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), \n",
    "                                     lr=0.00002, \n",
    "                                     betas=(0., 0.9),\n",
    "                                     weight_decay=0.001)\n",
    "\n",
    "gp_loss = GradientPenaltyLoss(\n",
    "    _metric_name='gp_loss',\n",
    "    discriminator=discriminator,\n",
    "    weight=10.0,\n",
    ")\n",
    "\n",
    "gen_loss = GeneratorLoss(\n",
    "    _metric_name='gen_loss'\n",
    ")\n",
    "\n",
    "disc_loss = DiscriminatorLoss(\n",
    "    _metric_name='disc_loss'\n",
    ")\n",
    "\n",
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train_wgan', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'gen_lr': 0.0002,\n",
    "            'disc_lr': 0.00002\n",
    "        },\n",
    "    )\n",
    "\n",
    "plot_callback = IntermediatePatchPlot(\n",
    "    name='plotter',\n",
    "    path=PLOT_DIR,\n",
    "    dataset=pds, # give it the patch dataset as opposed to the cached dataset\n",
    "    plot_metrics=[SSIM(_metric_name='ssim'), PSNR(_metric_name='psnr')],\n",
    "    figsize=(20, 25),\n",
    "    show_plot=False,\n",
    ")\n",
    "\n",
    "wgan_trainer = WGaNTrainer(\n",
    "    dataset=cds,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    patience=20, # setting this to prevent unwanted early termination here\n",
    "    device='cuda',\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gen_optimizer=generator_optimizer,\n",
    "    disc_optimizer=discriminator_optimizer,\n",
    "    generator_loss_fn=gen_loss,\n",
    "    discriminator_loss_fn=disc_loss,\n",
    "    gradient_penalty_fn=gp_loss,\n",
    "    discriminator_update_freq=1,\n",
    "    generator_update_freq=2,\n",
    "    callbacks=[mlflow_logger_callback, plot_callback],\n",
    "    metrics={'ssim': SSIM(_metric_name='ssim'), \n",
    "             'psnr': PSNR(_metric_name='psnr')},\n",
    ")\n",
    "\n",
    "wgan_trainer.train()\n",
    "\n",
    "del generator\n",
    "del wgan_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # wGaN GP example with mlflow logger callback and alternative early termination loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early termination at epoch 9 with best validation metric 0.21918950974941254\n"
     ]
    }
   ],
   "source": [
    "generator = UNet(\n",
    "    n_channels=1,\n",
    "    n_classes=1\n",
    ")\n",
    "\n",
    "discriminator = GlobalDiscriminator(\n",
    "    n_in_channels = 2,\n",
    "    n_in_filters = 64,\n",
    "    _conv_depth = 4,\n",
    "    _pool_before_fc = True\n",
    ")\n",
    "\n",
    "generator_optimizer = optim.Adam(generator.parameters(), \n",
    "                                 lr=0.0002, \n",
    "                                 betas=(0., 0.9))\n",
    "discriminator_optimizer = optim.Adam(discriminator.parameters(), \n",
    "                                     lr=0.00002, \n",
    "                                     betas=(0., 0.9),\n",
    "                                     weight_decay=0.001)\n",
    "\n",
    "gp_loss = GradientPenaltyLoss(\n",
    "    _metric_name='gp_loss',\n",
    "    discriminator=discriminator,\n",
    "    weight=10.0,\n",
    ")\n",
    "\n",
    "gen_loss = GeneratorLoss(\n",
    "    _metric_name='gen_loss'\n",
    ")\n",
    "\n",
    "disc_loss = DiscriminatorLoss(\n",
    "    _metric_name='disc_loss'\n",
    ")\n",
    "\n",
    "mlflow_logger_callback = MlflowLogger(\n",
    "        name='mlflow_logger',\n",
    "        mlflow_uri=MLFLOW_DIR / 'mlruns',\n",
    "        mlflow_experiment_name='Default',\n",
    "        mlflow_start_run_args={'run_name': 'example_train_wgan_mae_early_term', 'nested': True},\n",
    "        mlflow_log_params_args={\n",
    "            'gen_lr': 0.0002,\n",
    "            'disc_lr': 0.00002\n",
    "        },\n",
    "    )\n",
    "\n",
    "wgan_trainer = WGaNTrainer(\n",
    "    dataset=cds,\n",
    "    batch_size=16,\n",
    "    epochs=20,\n",
    "    patience=5, # lower patience here\n",
    "    device='cuda',\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    gen_optimizer=generator_optimizer,\n",
    "    disc_optimizer=discriminator_optimizer,\n",
    "    generator_loss_fn=gen_loss,\n",
    "    discriminator_loss_fn=disc_loss,\n",
    "    gradient_penalty_fn=gp_loss,\n",
    "    discriminator_update_freq=1,\n",
    "    generator_update_freq=2,\n",
    "    callbacks=[mlflow_logger_callback],\n",
    "    metrics={'ssim': SSIM(_metric_name='ssim'), \n",
    "             'psnr': PSNR(_metric_name='psnr'),\n",
    "             'mae': MetricsWrapper(_metric_name='mae', module=nn.L1Loss()) # use a wrapper for torch nn L1Loss\n",
    "             },\n",
    "    early_termination_metric = 'mae' # update early temrination loss with the supplied L1Loss/mae metric instead of the default GaN generator loss\n",
    ")\n",
    "\n",
    "wgan_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speckle_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
